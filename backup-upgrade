ETCDCTL_API=3 etcdctl --endpoints=https://[127.0.0.1]:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt \
     --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key \
     snapshot save /opt/snapshot-pre-boot.db

////don't use endpoint option when you are on master node

////the path after "save" is given in the question

ETCDCTL_API=3 etcdctl  --data-dir /var/lib/etcd-from-backup \
     snapshot restore /opt/snapshot-pre-boot.db
// then you shoul go to etcd.yaml and change the volume path data to /var/lib/etcd-from-backup

*****************************Upgrade*********************
1/kubectl drain master --ignore-deamonsets
2/ apt update 
apt install kubeadm=1.19.0-00
kubeadm upgrade apply v1.19.0-00
apt install kubelet=1.19.0-00 
sudo systemctl daemon-reload
systemctl restart kubelet
3/kubectl uncordon master

4/ then the same for woker node
kubectl drain node01 --ignore-deamonsets
ssh node01 
///repeat all steps
apt update 
apt install kubeadm=1.19.0-00
kubeadm upgrade apply v1.19.0-00
kubeadm upgrade node
apt install kubelet=1.19.0-00 
sudo systemctl daemon-reload
systemctl restart kubelet
kubectl uncordon node01

////////////note////////
if first the cluster is on  master node, you are going to do all steps of master nodes without ssh as you are already in it.
Nexttt when you'll start upgrading worker node, meke the drain first and then, ssh into that worker node


////////////////////////////////////check boken node///////////
journalctl -u kubelet
ssh node01
service kubelet start

/////////////////mark unscheduble or to take for maintenance///////////
kubectl drain nodeName --ignore-deamonsets  /////when it says make unscheduble
kubectl cordon nodeName //when it says mark it unscheduble but do not remove any apps running onit 
kubectl uncordon nodeName
